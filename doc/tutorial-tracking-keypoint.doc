/**

\page tutorial-tracking-keypoint Tutorial: Keypoint tracking
\tableofcontents

\section tracking_keypoint_klt KLT tracker

With ViSP it is possible to track keypoints using OpenCV KLT tracker, an implementation of the Kanade-Lucas-Tomasi feature tracker. The following example code available in tutorial-klt-tracker.cpp shows how to use ViSP vpKltOpencv class to this end. This class is a wrapper over the OpenCV KLT tracker implementation.

\include tutorial-klt-tracker.cpp

The video shows the result of the tracking:

\htmlonly
<iframe width="420" height="315" src="http://www.youtube.com/embed/ZYOG4kJPtaM?rel=0" frameborder="0" allowfullscreen></iframe>
\endhtmlonly

And here is the line by line explanation of the source : 

\code
#include <visp/vpImageConvert.h>
#include <visp/vpKltOpencv.h>
#include <visp/vpDisplayOpenCV.h>
#include <visp/vpVideoReader.h>
\endcode

We include here the headers that define the corresponding classes. vpImageConvert class will be used to convert ViSP images implemented in vpImage class into OpenCV IplImage structure used as an entry by the KLT tracker. Then we include the header of vpKltOpencv class which is the wrapper over OpenCV KLT tracker implementation. We need also to include a device to display the images. We retain vpDisplayOpenCV that works on Unix and Windows since OpenCV is mandatory by the tracker. Finally we include vpVideoReader header that will be used to read an mpeg input stream.

\code
#if (VISP_HAVE_OPENCV_VERSION >= 0x010100) && defined(VISP_HAVE_FFMPEG)
\endcode

We use the previous macro to ensure that OpenCV at least version 1.1.0 requested by the tracker and the image viewer, and ffmpeg requested to read the video stream are available.

\code
  vpVideoReader reader;
  reader.setFileName("video-postcard.mpeg");
\endcode

The program starts by the creation of a vpVideoReader instance able to extract all the images of the video file \c video-postcard.mpeg. Here, the video should be in the same folder than the binary.

\code
  vpImage<unsigned char> I;
  reader.acquire(I);
\endcode
Returns the first image of the video in the gray level ViSP image container \c I.

\code
  IplImage * cvI = NULL;
  vpImageConvert::convert(I, cvI);
\endcode

Then we convert \c I into \c cvI, an image in OpenCV IplImage format that will be used by the tracker.

\code
  vpDisplayOpenCV d(I, 0, 0, "Klt tracking");
  vpDisplay::display(I);
  vpDisplay::flush(I);
\endcode
Create a window associated to \c I, at position (0,0) in the screen, with "Klt tracking" as title, and display image \c I. 
 
\code
  vpKltOpencv tracker;

  tracker.setMaxFeatures(200);
  tracker.setWindowSize(10);
  tracker.setQuality(0.01);
  tracker.setMinDistance(15);
  tracker.setHarrisFreeParameter(0.04);
  tracker.setBlockSize(9);
  tracker.setUseHarris(1);
  tracker.setPyramidLevels(3);

  tracker.initTracking(cvI);
\endcode
 
Create an instance of the tracker, set parameters of the Harris keypoint detector and finally initialize the tracker on \c cvI image.

\code
  while ( ! reader.end() )
  {
    reader.acquire(I);
    vpImageConvert::convert(I, cvI);
    vpDisplay::display(I);
    
    tracker.track(cvI);
    tracker.display(I, vpColor::red);
    
    vpDisplay::flush(I);
  }
\endcode

Until the end of the video is not reached, we get \c I the next image in ViSP format, display and convert it in IplImage format. Then we track the Harris keypoints using KLT tracker before displaying the keypoints that are tracked with a red cross.

\code
  vpDisplay::getClick(I);
\endcode
We are waiting a mouse click event on image \c I to end the program.

With the following line, we release the memory allocated for the OpenCV IplImage \c cvI before ending the program.

\code
  cvReleaseImage(&cvI);
\endcode

\section tracking_keypoint_klt_init KLT tracker with re-initialisation

Once initialized, the number of tracked features decreases over the time. Depending on a criteria, it may sense to detect and track new features online. A possible criteria is for example to compare the number of currently tracked features to the initial number of detected features. If less than a given percentage of features are tracked, you can start a new detection. 

To get the number of detected or tracked features just call:

\code
  tracker.getNbFeatures();
\endcode

Then the idea is to add the previously tracked features to the list of features that are detected.

The example tutorial-klt-tracker-with-reinit.cpp shows how to do that. In that example we start a new detection on frame 25. Compared to the previous code available in tutorial-klt-tracker.cpp we add the following lines:

\code
      if (reader.getFrameIndex() == 25) {
        std::cout << "Re initialize the tracker" << std::endl;

        // Save of previous features
        int prev_nfeatures = tracker.getNbFeatures();
        float x, y;
        int id, j=0;

        CvPoint2D32f *prev_features = (CvPoint2D32f*)cvAlloc(prev_nfeatures*sizeof(CvPoint2D32f));

        for (int i=0; i <prev_nfeatures ; i ++) {
          tracker.getFeature(i, id, x, y);
          prev_features[i].x=x;
          prev_features[i].y=y;
        }

        // Start a new feature detection
        tracker.initTracking(cvI);

        // Add previous features if they are not to close to detected one
        float distance, minDistance_ = 2.f;// choose to keep old points distant of 2
        bool is_redundant;
        for(int i = tracker.getNbFeatures() ;
            j<prev_nfeatures && i<tracker.getMaxFeatures() ;
            j++){
          // Test if a previous feature is not redundant with new the one that are newly detected
          is_redundant = false;
          for(int k=0; k<tracker.getNbFeatures(); k++){
            tracker.getFeature(k,id,x,y);
            distance = sqrt(vpMath::sqr(x-prev_features[j].x) + vpMath::sqr(y-prev_features[j].y));
            if(distance < minDistance_){
              is_redundant = true;
              break;
            }
          }
          if(is_redundant)
            continue;
      
          tracker.addFeature(i, prev_features[j].x, prev_features[j].y);
          i++;
        }
        cvFree(&prev_features);
      }

      tracker.track(cvI);
\endcode

In this code we do the following:
- save the features that are tracked until now
- initialize the tracker to detect new features
- parse all the saved features and compare them to the newly detected features. If a previous feature is close in terms of geometric distanceto a newly detected one, it is rejected (in our case less than 2 pixels). If not, it is added to the list of detected features. 
 
You are now ready to see the next \ref tutorial-tracking-me.

*/
